{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b33a9219-153f-4531-9d19-25df9381e3c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.6.5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ccxt\n",
    "import talib\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from script.fetch_history_data import binance_fetch_history_price, binance_single_fetch_history_price\n",
    "from script.preprocess import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from script.transformer_timestep import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ad5bb89-e846-4393-aec9-4016e09fcfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seq_len = 128\n",
    "d_k = 256\n",
    "d_v = 256\n",
    "n_heads = 12\n",
    "ff_dim = 256\n",
    "valid_percent = 20\n",
    "test_percent = 10\n",
    "\n",
    "target_column='Close_MA_ptc_10'\n",
    "pearson_corr_cutoff = 0.2\n",
    "\n",
    "# with open('multi_factor_v2.0.1.pickle', 'rb') as input_pickle:\n",
    "#     multi_factor_dic = pickle.load(input_pickle)\n",
    "\n",
    "# zscore_col = multi_factor_dic['zscore'][0]\n",
    "# zscore_std = multi_factor_dic['zscore'][1]\n",
    "# zscore_mean = multi_factor_dic['zscore'][2]\n",
    "# input_col = multi_factor_dic['input_col']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67cfc83f-7ab5-4344-85cc-1ceab41a2b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_z_score_input_format(df_cal):\n",
    "    for col in zscore_col:\n",
    "        df_cal[col] = (df_cal[col] - zscore_mean) / zscore_std\n",
    "    df_cal['Volume_zscore'] = (df_cal['Volume'] - vol_zscore_mean) / vol_zscore_std\n",
    "    return df_cal[input_col], df_cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e442c01b-82e3-4756-a886-46fc10547588",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = binance_fetch_history_price(coin='BTC/USDT', timeframe='1h', start_date='2019-09-10')\n",
    "timeframes = [10,20,40,60,80,100,120,140,160,180,200]\n",
    "df_cal = calculate_technical_indicators(df, timeframes=timeframes)\n",
    "df_train, df_val, df_test = preprocess_train_test_split(df_cal, valid_percent=valid_percent, test_percent=test_percent)\n",
    "#df_cal.to_pickle('./data/multi_factor_v2.0.2.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff2e2cd-24ab-4a5f-92a1-b64850647cf6",
   "metadata": {},
   "source": [
    "#### Generate the Z-score std mean dictionary & Using pearson correlation to filter features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d0cf000-809a-43fa-b5b1-85267a7259ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cal = pd.read_pickle('./data/multi_factor_v2.0.2.pickle')\n",
    "df_train, df_val, df_test = preprocess_train_test_split(df_cal, valid_percent=valid_percent, test_percent=test_percent)\n",
    "df_cal_drop_col = df_train.copy()\n",
    "\n",
    "# select MA columns to calculate Z-score\n",
    "#del df_cal_drop_col['Timestamp']\n",
    "ma_ptc_col = [col for col in df_cal_drop_col.columns if 'MA_ptc' in col and 'Volume' not in col and col != 'Timestamp']\n",
    "ma_ptc_col += ['ZhangDieFu', 'ZhenFu']\t\n",
    "zscore_std = df_cal_drop_col[ma_ptc_col].values.reshape(-1).std()\n",
    "zscore_mean = df_cal_drop_col[ma_ptc_col].values.reshape(-1).mean()\n",
    "\n",
    "\n",
    "# select Volume to calculate Z-score    \n",
    "vol_zscore_std = df_cal_drop_col['Volume'].values.reshape(-1).std()\n",
    "vol_zscore_mean = df_cal_drop_col['Volume'].values.reshape(-1).mean()\n",
    "df_cal_drop_col['Volume_zscore'] = (df_cal_drop_col['Volume'] - vol_zscore_mean) / vol_zscore_std\n",
    "\n",
    "\n",
    "# # select Volume_ma_ptc_col to calculate Z-score    \n",
    "# vol_ma_col = [col for col in df_cal_drop_col.columns if 'Volume_MA' in col and 'ptc' not in col and col != 'Timestamp']\n",
    "# vol_ma_zscore_std = df_cal_drop_col[vol_ma_col].values.reshape(-1).std()\n",
    "# vol_ma_zscore_mean = df_cal_drop_col[vol_ma_col].values.reshape(-1).mean()\n",
    "# for col in vol_ma_col:\n",
    "#     df_cal_drop_col[col] = (df_cal_drop_col[col] - vol_ma_zscore_mean) / vol_ma_zscore_std\n",
    "\n",
    "# # select Volume_ma_ptc_col to calculate Z-score    \n",
    "# vol_ma_ptc_col = [col for col in df_cal_drop_col.columns if 'Volume_MA_ptc_' in col and col != 'Timestamp']\n",
    "# vol_ma_ptc_zscore_std = df_cal_drop_col[vol_ma_ptc_col].values.reshape(-1).std()\n",
    "# vol_ma_ptc_zscore_mean = df_cal_drop_col[vol_ma_ptc_col].values.reshape(-1).mean()\n",
    "# for col in vol_ma_ptc_col:\n",
    "#     df_cal_drop_col[col] = (df_cal_drop_col[col] - vol_ma_ptc_zscore_mean) / vol_ma_ptc_zscore_std\n",
    "\n",
    "# pearson corr filter\n",
    "filterd_col = [col for col in df_cal_drop_col.columns[(df_cal_drop_col.corr()[target_column].abs() >= pearson_corr_cutoff)]]\n",
    "#minmax_df = df_cal_drop_col[filterd_col]\n",
    "\n",
    "# save z-score to dictionary\n",
    "multi_factor_dic = {}\n",
    "multi_factor_dic['zscore'] = [ma_ptc_col, zscore_std, zscore_mean]\n",
    "multi_factor_dic['vol_zscore'] = ['Volume', vol_zscore_std, vol_zscore_mean]\n",
    "#multi_factor_dic['vol_ma_ptc_zscore'] = [vol_ma_ptc_col, vol_ma_ptc_zscore_std, vol_ma_ptc_zscore_mean]\n",
    "multi_factor_dic['input_col'] = filterd_col + ['Volume_zscore']\n",
    "\n",
    "with open('multi_factor_v2.0.3.pickle', 'wb') as input_pickle:\n",
    "    pickle.dump(multi_factor_dic, input_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8e1f57f-98c6-4838-bd4a-0d01acb9a0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10023461134264107"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cal_drop_col.corr()[target_column].abs()['Volume_zscore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb8a7141-1446-4f41-bdd0-3b6ff622fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('multi_factor_v2.0.3.pickle', 'rb') as input_pickle:\n",
    "    multi_factor_dic = pickle.load(input_pickle)\n",
    "\n",
    "zscore_col = multi_factor_dic['zscore'][0]\n",
    "zscore_std = multi_factor_dic['zscore'][1]\n",
    "zscore_mean = multi_factor_dic['zscore'][2]\n",
    "vol_zscore_col = multi_factor_dic['vol_zscore'][0]\n",
    "vol_zscore_std = multi_factor_dic['vol_zscore'][1]\n",
    "vol_zscore_mean = multi_factor_dic['vol_zscore'][2]\n",
    "input_col = multi_factor_dic['input_col']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "653651ef-9a5b-411b-985c-e6a56ae88cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_zscore, df_train_zscore_total = calculate_z_score_input_format(df_train)\n",
    "df_val_zscore, df_val_zscore_total = calculate_z_score_input_format(df_val)\n",
    "df_test_zscore, df_test_zscore_total = calculate_z_score_input_format(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73c6d4a1-305d-418b-9ff9-e95d7a7bfbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = preprocess_sequence_data(df_train_zscore, target_column=target_column, seq_len=seq_len)\n",
    "X_val, y_val = preprocess_sequence_data(df_val_zscore, target_column=target_column, seq_len=seq_len)\n",
    "X_test, y_test = preprocess_sequence_data(df_test_zscore, target_column=target_column, seq_len=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6503e9-d1a7-45d7-ab00-a2f76333bd5d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for build z score dictionary\n",
    "\n",
    "# df = pd.read_pickle('./data/multi_factor_v2.0.1.pickle')\n",
    "# df_cal_drop_col = df.copy()\n",
    "# del df_cal_drop_col['Timestamp']\n",
    "# ma_ptc_col = [col for col in df_cal_drop_col.columns if 'MA_ptc' in col and 'Volume' not in col and col != 'Timestamp']\n",
    "# ma_ptc_col += ['ZhangDieFu', 'ZhenFu']\n",
    "# zscore_std = df_cal_drop_col[ma_ptc_col].values.reshape(-1).std()\n",
    "# zscore_mean = df_cal_drop_col[ma_ptc_col].values.reshape(-1).mean()\n",
    "\n",
    "# for col in ma_ptc_col:\n",
    "#     df_cal_drop_col[col] = (df_cal_drop_col[col] - zscore_mean) / zscore_std\n",
    "# # pearson corr filter\n",
    "# filterd_col = [col for col in df_cal_drop_col.columns[(df_cal_drop_col.corr()[target_column].abs() >= pearson_corr_cutoff)]]\n",
    "\n",
    "# multi_factor_dic = {}\n",
    "# multi_factor_dic['zscore'] = [ma_ptc_col, zscore_std, zscore_mean]\n",
    "# multi_factor_dic['input_col'] = filterd_col\n",
    "\n",
    "# with open('multi_factor_v2.0.1.pickle', 'wb') as input_pickle:\n",
    "#     pickle.dump(multi_factor_dic, input_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d782080e-41ff-486f-8d38-879790907106",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 02:52:31.289634: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-22 02:52:32.132155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44773 MB memory:  -> device: 0, name: NVIDIA Quadro RTX 8000, pci bus id: 0000:21:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 95)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time2_vector (Time2Vector)      (None, 128, 2)       512         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 128, 97)      0           input_1[0][0]                    \n",
      "                                                                 time2_vector[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "transformer_encoder (Transforme (None, 128, 97)      1251654     concatenate[0][0]                \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "transformer_encoder_1 (Transfor (None, 128, 97)      1251654     transformer_encoder[0][0]        \n",
      "                                                                 transformer_encoder[0][0]        \n",
      "                                                                 transformer_encoder[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "transformer_encoder_2 (Transfor (None, 128, 97)      1251654     transformer_encoder_1[0][0]      \n",
      "                                                                 transformer_encoder_1[0][0]      \n",
      "                                                                 transformer_encoder_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 128)          0           transformer_encoder_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           8256        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            65          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,763,795\n",
      "Trainable params: 3,763,795\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the transformer model\n",
    "feature_count = X_train.shape[2]\n",
    "def create_model():\n",
    "    '''Initialize time and transformer layers'''\n",
    "    time_embedding = Time2Vector(seq_len)\n",
    "    attn_layer1 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "    attn_layer2 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "    attn_layer3 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "\n",
    "    '''Construct model'''\n",
    "    in_seq = Input(shape=(seq_len, feature_count))\n",
    "    x = time_embedding(in_seq)\n",
    "    x = Concatenate(axis=-1)([in_seq, x])\n",
    "    x = attn_layer1((x, x, x))\n",
    "    x = attn_layer2((x, x, x))\n",
    "    x = attn_layer3((x, x, x))\n",
    "    x = GlobalAveragePooling1D(data_format='channels_first')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    out = Dense(1, activation='linear')(x)\n",
    "    model = Model(inputs=in_seq, outputs=out)\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,\n",
    "                                                                decay_steps=10000,\n",
    "                                                                decay_rate=0.9)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mae','mape'])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()\n",
    "\n",
    "callback = tf.keras.callbacks.ModelCheckpoint('./model_weight/transformer_btc_multi_factor_v2.0.3.hdf5', \n",
    "                                              monitor='val_loss', \n",
    "                                              save_best_only=True, \n",
    "                                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fcaa3b-6b3c-42cf-a84d-3cdb609a949b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 02:52:39.400937: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 02:53:04.676075: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "863/863 [==============================] - 611s 678ms/step - loss: 0.6180 - mae: 0.5199 - mape: 576.0943 - val_loss: 0.3616 - val_mae: 0.4194 - val_mape: 611.0764\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.36158, saving model to ./model_weight/transformer_btc_multi_factor_v2.0.3.hdf5\n",
      "Epoch 2/35\n",
      "250/863 [=======>......................] - ETA: 6:33 - loss: 0.4537 - mae: 0.4414 - mape: 532.5446"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=35, \n",
    "                    callbacks=[callback],\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b0dd92-2287-4f91-9143-32ae5f259944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./model_weight/transformer_btc_multi_factor_v2.0.3.hdf5',\n",
    "                                   custom_objects={'Time2Vector': Time2Vector, \n",
    "                                                   'SingleAttention': SingleAttention,\n",
    "                                                   'MultiAttention': MultiAttention,\n",
    "                                                   'TransformerEncoder': TransformerEncoder})\n",
    "\n",
    "test_pred  = model.predict(X_test)\n",
    "test_eval  = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Data - Loss: {:.4f}, MAE: {:.4f}'.format(test_eval[0], test_eval[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018704bc-bcf5-4dfb-b280-5e53f877f69d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #zscore = (x - mean) / std\n",
    "# def restore_zscore_close_price(df, target_col='pred_Close_MA_ptc_10', moving_avg_step=10, seq_len=128):\n",
    "#     input_df = df.copy()\n",
    "#     # restore min mnax\n",
    "#     input_df[target_col][seq_len:] = input_df[target_col][seq_len:]*zscore_std + zscore_mean\n",
    "#     restored_close_list = []\n",
    "#     for idx in range(seq_len, len(input_df)):\n",
    "#         previois_avg     = input_df.loc[idx - moving_avg_step : idx - 1 ,'Close'].mean()\n",
    "#         close_avg        = previois_avg * (input_df[target_col][idx] + 1)\n",
    "#         restored_close   = (close_avg * moving_avg_step) - (input_df.loc[idx - (moving_avg_step -1) : idx - 1, 'Close'].sum())\n",
    "#         restored_close_list.append(restored_close)\n",
    "#     input_df['pred_Close'] = '-'\n",
    "#     input_df['pred_Close'][seq_len:] = restored_close_list\n",
    "#     return input_df\n",
    "\n",
    "\n",
    "#zscore = (x - mean) / std\n",
    "# def restore_zscore_close_price_v2(pred_df, all_col_df, target_col='pred_Close_MA_ptc_10', moving_avg_step=10, seq_len=128):\n",
    "#     # copy close, close_MA_10, to pred_df\n",
    "#     input_df = pred_df.copy()\n",
    "#     input_df_all_columns = all_col_df.copy()\n",
    "#     input_df['Close'] = input_df_all_columns['Close'][input_df.index]\n",
    "#     input_df['Close_MA_10'] = input_df_all_columns['Close_MA_10'][input_df.index]\n",
    "    \n",
    "#     # restore min mnax\n",
    "#     input_df = input_df.reset_index(drop=True)\n",
    "#     input_df[target_col][seq_len:] = input_df[target_col][seq_len:]*zscore_std + zscore_mean\n",
    "#     restored_close_list = []\n",
    "#     for idx in range(seq_len, len(input_df)):\n",
    "#         previois_avg     = input_df['Close_MA_10'][idx-1]\n",
    "#         close_avg        = previois_avg * (input_df[target_col][idx] + 1)\n",
    "#         restored_close   = (close_avg * moving_avg_step) - (input_df.loc[idx - (moving_avg_step -1) : idx - 1, 'Close'].sum())\n",
    "#         restored_close_list.append(restored_close)\n",
    "#     input_df['pred_Close'] = '-'\n",
    "#     input_df['pred_Close'][seq_len:] = restored_close_list\n",
    "#     print(len(restored_close_list))\n",
    "#     return input_df, restored_close_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55549f73-5254-4e0e-b937-6e079d5b697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_restore_close(test_pred, df_zscore_total, seq_len=128):\n",
    "    df_zscore_output = df_zscore_total.reset_index(drop=True).copy()\n",
    "    df_zscore_output['pred_Close']='-'\n",
    "    # 128~len(df)\n",
    "    for i in range(seq_len, len(df_zscore_output)):\n",
    "        # restore the model predicted_ptc\n",
    "        pred_ptc = test_pred[i-seq_len]*zscore_std + zscore_mean\n",
    "        # choose the single_df[0:128] (index 0~127) \n",
    "        single_df = df_zscore_output[i-seq_len:i]\n",
    "        # take the final MA_10\n",
    "        pre_MA = single_df['Close_MA_10'][single_df.index[-1]]\n",
    "        # final MA_10* pred_ptc = pred_MA10\n",
    "        close_MA = pre_MA*(pred_ptc+1)\n",
    "        # pred_MA_10*10 - pre 9 Close = pred_Close\n",
    "        pred_close = close_MA*10 - single_df['Close'][-9:].sum()\n",
    "        df_zscore_output['pred_Close'][i] = pred_close\n",
    "    return df_zscore_output\n",
    "\n",
    "def restore_zscore_close_price_v3(test_pred, df_zscore_total, seq_len=128):\n",
    "    df_zscore_output = df_zscore_total.reset_index(drop=True).copy()\n",
    "    df_zscore_output['pred_Close']='-'\n",
    "    # 128~len(df)\n",
    "    for i in range(seq_len, len(df_zscore_output)):\n",
    "        # restore the model predicted_ptc\n",
    "        pred_ptc = test_pred[i-seq_len][0]*zscore_std + zscore_mean\n",
    "        # choose the single_df[0:128] (index 0~127) \n",
    "        single_df = df_zscore_output[i-seq_len:i]\n",
    "        # take the final MA_10\n",
    "        pre_MA = single_df['Close_MA_10'][single_df.index[-1]]\n",
    "        # final MA_10* pred_ptc = pred_MA10\n",
    "        close_MA = pre_MA*(pred_ptc+1)\n",
    "        # pred_MA_10*10 - pre 9 Close = pred_Close\n",
    "        pred_close = close_MA*10 - single_df['Close'][-9:].sum()\n",
    "        df_zscore_output['pred_Close'][i] = pred_close\n",
    "    return df_zscore_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f7db0d-9f4a-4229-878e-89324fec0be7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_output = restore_zscore_close_price_v3(test_pred, df_test_zscore_total, seq_len=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9e1e1931-ae37-401f-b2ed-8ee11fb012c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = validation_restore_close(y_test, df_test_zscore_total, seq_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2e3434-c878-4999-a08b-9a3216d457ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "restored_df = df_output.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92461fde-9869-4a72-ab0c-a7914b488ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw all testing data prediction fig\n",
    "\n",
    "fig = plt.figure(figsize=(15,20))\n",
    "st = fig.suptitle(\"Moving Average with Z-score\", fontsize=22)\n",
    "st.set_y(0.92)\n",
    "\n",
    "#Plot training data results\n",
    "ax11 = fig.add_subplot(311)\n",
    "ax11.plot(restored_df['Close'][seq_len:].values, label='BTC Closing Returns')\n",
    "ax11.plot(restored_df['pred_Close'][seq_len:].values, label='Predicted BTC Closing Returns')\n",
    "ax11.set_title(\"Testing Data\", fontsize=18)\n",
    "ax11.set_xlabel('Date')\n",
    "ax11.set_ylabel('BTC Closing Returns')\n",
    "ax11.legend(loc=\"best\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3624ed-f6ac-4c01-9ee7-8ee646e9b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw with first 400 testing data prediction\n",
    "seq_len = 128\n",
    "fig = plt.figure(figsize=(15,20))\n",
    "st = fig.suptitle(\"Moving Average with Z-score\", fontsize=22)\n",
    "st.set_y(0.92)\n",
    "\n",
    "#Plot training data results\n",
    "ax11 = fig.add_subplot(311)\n",
    "ax11.plot(restored_df['Close'][seq_len:seq_len+400].values, label='BTC Closing Returns')\n",
    "ax11.plot(restored_df['pred_Close'][seq_len:seq_len+400].values, label='Predicted BTC Closing Returns')\n",
    "ax11.set_title(\"Testing Data\", fontsize=18)\n",
    "ax11.set_xlabel('Date')\n",
    "ax11.set_ylabel('BTC Closing Returns')\n",
    "ax11.legend(loc=\"best\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819a0b90-7a98-48e9-b408-6452577e8d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5de941b-b632-4d4b-9c86-7577c1314043",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.to_pickle('./output_file/20230322_multi_factor_v2.0.3_testing.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381e28c6-40ab-4194-bfab-3851d85d9c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
