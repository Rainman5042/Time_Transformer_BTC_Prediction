{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b33a9219-153f-4531-9d19-25df9381e3c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.6.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.5 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.6.5\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "development python version:3.8.13\n",
    "author: Siao-Yu Jian\n",
    "function: Data preprocess and Model training for ETH\n",
    "version history:\n",
    "                2023.03.23      version v2.0.3      initial version\n",
    "                2023.03.24      version v2.0.4      change train test split to sklearn train_test_split for fix price shiffting     \n",
    "'''\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ccxt\n",
    "import talib\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from script.fetch_history_data import binance_fetch_history_price, binance_single_fetch_history_price\n",
    "from script.preprocess import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from script.transformer_timestep import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ad5bb89-e846-4393-aec9-4016e09fcfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seq_len = 128\n",
    "d_k = 256\n",
    "d_v = 256\n",
    "n_heads = 12\n",
    "ff_dim = 256\n",
    "valid_percent = 20\n",
    "test_percent = 10\n",
    "\n",
    "target_column='Close_MA_ptc_10'\n",
    "pearson_corr_cutoff = 0.2\n",
    "\n",
    "model_weight_path = './model_weight/transformer_eth_multi_factor_v2.0.4.hdf5'\n",
    "# with open('multi_factor_v2.0.1.pickle', 'rb') as input_pickle:\n",
    "#     multi_factor_dic = pickle.load(input_pickle)\n",
    "\n",
    "# zscore_col = multi_factor_dic['zscore'][0]\n",
    "# zscore_std = multi_factor_dic['zscore'][1]\n",
    "# zscore_mean = multi_factor_dic['zscore'][2]\n",
    "# input_col = multi_factor_dic['input_col']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67cfc83f-7ab5-4344-85cc-1ceab41a2b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_z_score_input_format(df_cal):\n",
    "    for col in zscore_col:\n",
    "        df_cal[col] = (df_cal[col] - zscore_mean) / zscore_std\n",
    "    df_cal['Volume_zscore'] = (df_cal['Volume'] - vol_zscore_mean) / vol_zscore_std\n",
    "    return df_cal[input_col], df_cal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec6d679-e03b-4007-8dde-54ac8ccc0434",
   "metadata": {},
   "source": [
    "## Data lock for hyper-parameter & trace bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e442c01b-82e3-4756-a886-46fc10547588",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = binance_fetch_history_price(coin='ETH/USDT', timeframe='1h', start_date='2019-09-10')\n",
    "timeframes = [10,20,40,60,80,100,120,140,160,180,200]\n",
    "df_cal = calculate_technical_indicators(df, timeframes=timeframes)\n",
    "#df_train, df_val, df_test = preprocess_train_test_split(df_cal, valid_percent=valid_percent, test_percent=test_percent)\n",
    "df_cal.to_pickle('./data/eth_multi_factor_v2.0.4.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff2e2cd-24ab-4a5f-92a1-b64850647cf6",
   "metadata": {},
   "source": [
    "#### Generate the Z-score std mean dictionary & Using pearson correlation to filter features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d0cf000-809a-43fa-b5b1-85267a7259ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cal = pd.read_pickle('./data/eth_multi_factor_v2.0.4.pickle')\n",
    "df_drop_timestamp = df_cal.copy()\n",
    "del df_drop_timestamp['Timestamp']\n",
    "# change to sklearn to split train test set\n",
    "df_train, df_test = train_test_split(df_drop_timestamp, random_state=0, train_size=0.9, shuffle=False)\n",
    "df_train, df_val = train_test_split(df_train, random_state=0, train_size=0.9, shuffle=False)\n",
    "#df_train, df_val, df_test = preprocess_train_test_split(df_cal, valid_percent=valid_percent, test_percent=test_percent)\n",
    "df_cal_drop_col = df_train.copy()\n",
    "\n",
    "# select MA columns to calculate Z-score\n",
    "#del df_cal_drop_col['Timestamp']\n",
    "ma_ptc_col = [col for col in df_cal_drop_col.columns if 'MA_ptc' in col and 'Volume' not in col and col != 'Timestamp']\n",
    "ma_ptc_col += ['ZhangDieFu', 'ZhenFu']\t\n",
    "zscore_std = df_cal_drop_col[ma_ptc_col].values.reshape(-1).std()\n",
    "zscore_mean = df_cal_drop_col[ma_ptc_col].values.reshape(-1).mean()\n",
    "\n",
    "\n",
    "# select Volume to calculate Z-score    \n",
    "vol_zscore_std = df_cal_drop_col['Volume'].values.reshape(-1).std()\n",
    "vol_zscore_mean = df_cal_drop_col['Volume'].values.reshape(-1).mean()\n",
    "df_cal_drop_col['Volume_zscore'] = (df_cal_drop_col['Volume'] - vol_zscore_mean) / vol_zscore_std\n",
    "\n",
    "\n",
    "# # select Volume_ma_ptc_col to calculate Z-score    \n",
    "# vol_ma_col = [col for col in df_cal_drop_col.columns if 'Volume_MA' in col and 'ptc' not in col and col != 'Timestamp']\n",
    "# vol_ma_zscore_std = df_cal_drop_col[vol_ma_col].values.reshape(-1).std()\n",
    "# vol_ma_zscore_mean = df_cal_drop_col[vol_ma_col].values.reshape(-1).mean()\n",
    "# for col in vol_ma_col:\n",
    "#     df_cal_drop_col[col] = (df_cal_drop_col[col] - vol_ma_zscore_mean) / vol_ma_zscore_std\n",
    "\n",
    "# # select Volume_ma_ptc_col to calculate Z-score    \n",
    "# vol_ma_ptc_col = [col for col in df_cal_drop_col.columns if 'Volume_MA_ptc_' in col and col != 'Timestamp']\n",
    "# vol_ma_ptc_zscore_std = df_cal_drop_col[vol_ma_ptc_col].values.reshape(-1).std()\n",
    "# vol_ma_ptc_zscore_mean = df_cal_drop_col[vol_ma_ptc_col].values.reshape(-1).mean()\n",
    "# for col in vol_ma_ptc_col:\n",
    "#     df_cal_drop_col[col] = (df_cal_drop_col[col] - vol_ma_ptc_zscore_mean) / vol_ma_ptc_zscore_std\n",
    "\n",
    "# pearson corr filter\n",
    "filterd_col = [col for col in df_cal_drop_col.columns[(df_cal_drop_col.corr()[target_column].abs() >= pearson_corr_cutoff)]]\n",
    "#minmax_df = df_cal_drop_col[filterd_col]\n",
    "\n",
    "# save z-score to dictionary\n",
    "multi_factor_dic = {}\n",
    "multi_factor_dic['zscore'] = [ma_ptc_col, zscore_std, zscore_mean]\n",
    "multi_factor_dic['vol_zscore'] = ['Volume', vol_zscore_std, vol_zscore_mean]\n",
    "#multi_factor_dic['vol_ma_ptc_zscore'] = [vol_ma_ptc_col, vol_ma_ptc_zscore_std, vol_ma_ptc_zscore_mean]\n",
    "multi_factor_dic['input_col'] = filterd_col + ['Volume_zscore']\n",
    "\n",
    "with open('./normalization/eth_multi_factor_v2.0.4.pickle', 'wb') as input_pickle:\n",
    "    pickle.dump(multi_factor_dic, input_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8e1f57f-98c6-4838-bd4a-0d01acb9a0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11029188522866228"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cal_drop_col.corr()[target_column].abs()['Volume_zscore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb8a7141-1446-4f41-bdd0-3b6ff622fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./normalization/eth_multi_factor_v2.0.4.pickle', 'rb') as input_pickle:\n",
    "    multi_factor_dic = pickle.load(input_pickle)\n",
    "\n",
    "zscore_col = multi_factor_dic['zscore'][0]\n",
    "zscore_std = multi_factor_dic['zscore'][1]\n",
    "zscore_mean = multi_factor_dic['zscore'][2]\n",
    "vol_zscore_col = multi_factor_dic['vol_zscore'][0]\n",
    "vol_zscore_std = multi_factor_dic['vol_zscore'][1]\n",
    "vol_zscore_mean = multi_factor_dic['vol_zscore'][2]\n",
    "input_col = multi_factor_dic['input_col']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "653651ef-9a5b-411b-985c-e6a56ae88cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_zscore, df_train_zscore_total = calculate_z_score_input_format(df_train)\n",
    "df_val_zscore, df_val_zscore_total = calculate_z_score_input_format(df_val)\n",
    "df_test_zscore, df_test_zscore_total = calculate_z_score_input_format(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73c6d4a1-305d-418b-9ff9-e95d7a7bfbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = preprocess_sequence_data(df_train_zscore, target_column=target_column, seq_len=seq_len)\n",
    "X_val, y_val = preprocess_sequence_data(df_val_zscore, target_column=target_column, seq_len=seq_len)\n",
    "X_test, y_test = preprocess_sequence_data(df_test_zscore, target_column=target_column, seq_len=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b6503e9-d1a7-45d7-ab00-a2f76333bd5d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for build z score dictionary\n",
    "\n",
    "# df = pd.read_pickle('./data/multi_factor_v2.0.1.pickle')\n",
    "# df_cal_drop_col = df.copy()\n",
    "# del df_cal_drop_col['Timestamp']\n",
    "# ma_ptc_col = [col for col in df_cal_drop_col.columns if 'MA_ptc' in col and 'Volume' not in col and col != 'Timestamp']\n",
    "# ma_ptc_col += ['ZhangDieFu', 'ZhenFu']\n",
    "# zscore_std = df_cal_drop_col[ma_ptc_col].values.reshape(-1).std()\n",
    "# zscore_mean = df_cal_drop_col[ma_ptc_col].values.reshape(-1).mean()\n",
    "\n",
    "# for col in ma_ptc_col:\n",
    "#     df_cal_drop_col[col] = (df_cal_drop_col[col] - zscore_mean) / zscore_std\n",
    "# # pearson corr filter\n",
    "# filterd_col = [col for col in df_cal_drop_col.columns[(df_cal_drop_col.corr()[target_column].abs() >= pearson_corr_cutoff)]]\n",
    "\n",
    "# multi_factor_dic = {}\n",
    "# multi_factor_dic['zscore'] = [ma_ptc_col, zscore_std, zscore_mean]\n",
    "# multi_factor_dic['input_col'] = filterd_col\n",
    "\n",
    "# with open('multi_factor_v2.0.1.pickle', 'wb') as input_pickle:\n",
    "#     pickle.dump(multi_factor_dic, input_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d782080e-41ff-486f-8d38-879790907106",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 15:36:50.149435: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-24 15:36:50.925860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44773 MB memory:  -> device: 0, name: NVIDIA Quadro RTX 8000, pci bus id: 0000:21:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 94)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time2_vector (Time2Vector)      (None, 128, 2)       512         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 128, 96)      0           input_1[0][0]                    \n",
      "                                                                 time2_vector[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "transformer_encoder (Transforme (None, 128, 96)      1238848     concatenate[0][0]                \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "transformer_encoder_1 (Transfor (None, 128, 96)      1238848     transformer_encoder[0][0]        \n",
      "                                                                 transformer_encoder[0][0]        \n",
      "                                                                 transformer_encoder[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "transformer_encoder_2 (Transfor (None, 128, 96)      1238848     transformer_encoder_1[0][0]      \n",
      "                                                                 transformer_encoder_1[0][0]      \n",
      "                                                                 transformer_encoder_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 128)          0           transformer_encoder_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           8256        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            65          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,725,377\n",
      "Trainable params: 3,725,377\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the transformer model\n",
    "feature_count = X_train.shape[2]\n",
    "def create_model():\n",
    "    '''Initialize time and transformer layers'''\n",
    "    time_embedding = Time2Vector(seq_len)\n",
    "    attn_layer1 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "    attn_layer2 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "    attn_layer3 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "\n",
    "    '''Construct model'''\n",
    "    in_seq = Input(shape=(seq_len, feature_count))\n",
    "    x = time_embedding(in_seq)\n",
    "    x = Concatenate(axis=-1)([in_seq, x])\n",
    "    x = attn_layer1((x, x, x))\n",
    "    x = attn_layer2((x, x, x))\n",
    "    x = attn_layer3((x, x, x))\n",
    "    x = GlobalAveragePooling1D(data_format='channels_first')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    out = Dense(1, activation='linear')(x)\n",
    "    model = Model(inputs=in_seq, outputs=out)\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,\n",
    "                                                                 decay_steps=10000,\n",
    "                                                                 decay_rate=0.9)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    #optimizer=tfa.optimizers.RectifiedAdam(0.001)\n",
    "    #loss_function='mae'\n",
    "    loss_function='mse'\n",
    "    model.compile(loss=loss_function, optimizer=optimizer, metrics=['mae','mape'])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()\n",
    "\n",
    "callback = tf.keras.callbacks.ModelCheckpoint(model_weight_path, \n",
    "                                              monitor='val_loss', \n",
    "                                              save_best_only=True, \n",
    "                                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43fcaa3b-6b3c-42cf-a84d-3cdb609a949b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 15:36:58.143588: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 15:37:24.151520: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407/730 [===============>..............] - ETA: 3:31 - loss: 0.5607 - mae: 0.5123 - mape: 192.6721"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=35, \n",
    "                    callbacks=[callback],\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b0dd92-2287-4f91-9143-32ae5f259944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = load_fine_tune_model(model_weight_path)\n",
    "\n",
    "train_pred  = model.predict(X_train)\n",
    "val_pred  = model.predict(X_val)\n",
    "test_pred  = model.predict(X_test)\n",
    "\n",
    "train_eval  = model.evaluate(X_train, y_train, verbose=0)\n",
    "val_eval  = model.evaluate(X_val, y_val, verbose=0)\n",
    "test_eval  = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Train Data - Loss: {:.4f}, MAE: {:.4f}'.format(train_eval[0], train_eval[1]))\n",
    "print('Val Data - Loss: {:.4f}, MAE: {:.4f}'.format(val_eval[0], val_eval[1]))\n",
    "print('Test Data - Loss: {:.4f}, MAE: {:.4f}'.format(test_eval[0], test_eval[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b8343b-642c-4a87-8487-67b4cd0b8726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print('Model before shiffting:')\n",
    "print('Train Data before shiftting:', mean_squared_error(train_pred.reshape(-1)[:], y_train[:]))\n",
    "print('Val Data before shiftting:', mean_squared_error(val_pred.reshape(-1)[:], y_val[:]))\n",
    "print('Test Data before shiftting:', mean_squared_error(test_pred.reshape(-1)[:], y_test[:]))\n",
    "print('\\nModel after shiffing:')\n",
    "print('Train Data after shiftting:', mean_squared_error(train_pred.reshape(-1)[1:], y_train[:-1]))\n",
    "print('Val Data after shiftting:', mean_squared_error(val_pred.reshape(-1)[1:], y_val[:-1]))\n",
    "print('Test Data after shiftting:', mean_squared_error(test_pred.reshape(-1)[1:], y_test[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6275f91-2ef3-4fef-a535-cf03fa57a750",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,20))\n",
    "st = fig.suptitle(\"Moving Average with Z-score\", fontsize=22)\n",
    "st.set_y(0.92)\n",
    "\n",
    "#Plot training data results\n",
    "ax11 = fig.add_subplot(311)\n",
    "ax11.plot(list(y_test)[:400], label='BTC Closing Returns')\n",
    "ax11.plot(list(test_pred.reshape(-1)[0:400]), label='Predicted BTC Closing Returns')\n",
    "ax11.set_title(\"Testing Data MA\", fontsize=18)\n",
    "ax11.set_xlabel('Date')\n",
    "ax11.set_ylabel('BTC Closing Returns')\n",
    "ax11.legend(loc=\"best\", fontsize=12)\n",
    "\n",
    "#Plot training data results\n",
    "ax11 = fig.add_subplot(312)\n",
    "ax11.plot(list(y_test)[0:400], label='BTC Closing Returns')\n",
    "ax11.plot(list(test_pred.reshape(-1)[1:401]), label='Predicted BTC Closing Returns')\n",
    "ax11.set_title(\"Testing Data MA after shifting 1hr move\", fontsize=18)\n",
    "ax11.set_xlabel('Date')\n",
    "ax11.set_ylabel('BTC Closing Returns')\n",
    "ax11.legend(loc=\"best\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f1bd28-a74b-4ea3-9c06-79fadc4bb9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271be552-9d66-43cf-8a94-0dc8c0e072ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55549f73-5254-4e0e-b937-6e079d5b697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_restore_close(test_pred, df_zscore_total, seq_len=128):\n",
    "    df_zscore_output = df_zscore_total.reset_index(drop=True).copy()\n",
    "    df_zscore_output['pred_Close']='-'\n",
    "    # 128~len(df)\n",
    "    for i in range(seq_len, len(df_zscore_output)):\n",
    "        # restore the model predicted_ptc\n",
    "        pred_ptc = test_pred[i-seq_len]*zscore_std + zscore_mean\n",
    "        # choose the single_df[0:128] (index 0~127) \n",
    "        single_df = df_zscore_output[i-seq_len:i]\n",
    "        # take the final MA_10\n",
    "        pre_MA = single_df['Close_MA_10'][single_df.index[-1]]\n",
    "        # final MA_10* pred_ptc = pred_MA10\n",
    "        close_MA = pre_MA*(pred_ptc+1)\n",
    "        # pred_MA_10*10 - pre 9 Close = pred_Close\n",
    "        pred_close = close_MA*10 - single_df['Close'][-9:].sum()\n",
    "        df_zscore_output['pred_Close'][i] = pred_close\n",
    "    return df_zscore_output\n",
    "\n",
    "def restore_zscore_close_price_v3(test_pred, df_zscore_total, seq_len=128):\n",
    "    df_zscore_output = df_zscore_total.reset_index(drop=True).copy()\n",
    "    df_zscore_output['pred_Close']='-'\n",
    "    # 128~len(df)\n",
    "    for i in range(seq_len, len(df_zscore_output)):\n",
    "        # restore the model predicted_ptc\n",
    "        pred_ptc = test_pred[i-seq_len][0]*zscore_std + zscore_mean\n",
    "        # choose the single_df[0:128] (index 0~127) \n",
    "        single_df = df_zscore_output[i-seq_len:i]\n",
    "        # take the final MA_10\n",
    "        pre_MA = single_df['Close_MA_10'][single_df.index[-1]]\n",
    "        # final MA_10* pred_ptc = pred_MA10\n",
    "        close_MA = pre_MA*(pred_ptc+1)\n",
    "        # pred_MA_10*10 - pre 9 Close = pred_Close\n",
    "        pred_close = close_MA*10 - single_df['Close'][-9:].sum()\n",
    "        df_zscore_output['pred_Close'][i] = pred_close\n",
    "    return df_zscore_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1e1931-ae37-401f-b2ed-8ee11fb012c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = validation_restore_close(y_test, df_test_zscore_total, seq_len=128)\n",
    "\n",
    "# draw all testing data prediction fig\n",
    "\n",
    "fig = plt.figure(figsize=(15,20))\n",
    "st = fig.suptitle(\"Moving Average with Z-score\", fontsize=22)\n",
    "st.set_y(0.92)\n",
    "\n",
    "#Plot training data results\n",
    "ax11 = fig.add_subplot(311)\n",
    "ax11.plot(test['Close'][seq_len:].values, label='BTC Closing Returns')\n",
    "ax11.plot(test['pred_Close'][seq_len:].values, label='Predicted BTC Closing Returns')\n",
    "ax11.set_title(\"Testing Data\", fontsize=18)\n",
    "ax11.set_xlabel('Date')\n",
    "ax11.set_ylabel('BTC Closing Returns')\n",
    "ax11.legend(loc=\"best\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f7db0d-9f4a-4229-878e-89324fec0be7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_output = restore_zscore_close_price_v3(test_pred, df_test_zscore_total, seq_len=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cedc5b-e7b5-4c6a-98e3-343a5d4a7993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_output.to_pickle('./output_file/20230322_multi_factor_v2.0.3_testing.pickle')\n",
    "# df_output = pd.read_pickle('./output_file/20230322_multi_factor_v2.0.3_testing.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2e3434-c878-4999-a08b-9a3216d457ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restored_df = df_output.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92461fde-9869-4a72-ab0c-a7914b488ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # draw all testing data prediction fig\n",
    "\n",
    "# fig = plt.figure(figsize=(15,20))\n",
    "# st = fig.suptitle(\"Moving Average with Z-score\", fontsize=22)\n",
    "# st.set_y(0.92)\n",
    "\n",
    "# #Plot training data results\n",
    "# ax11 = fig.add_subplot(311)\n",
    "# ax11.plot(restored_df['Close'][seq_len:seq_len+200].values, label='BTC Closing Returns')\n",
    "# ax11.plot(restored_df['pred_Close'][seq_len:seq_len+200].values, label='Predicted BTC Closing Returns')\n",
    "# ax11.set_title(\"Testing Data\", fontsize=18)\n",
    "# ax11.set_xlabel('Date')\n",
    "# ax11.set_ylabel('BTC Closing Returns')\n",
    "# ax11.legend(loc=\"best\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3624ed-f6ac-4c01-9ee7-8ee646e9b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # draw with first 400 testing data prediction\n",
    "# seq_len = 128\n",
    "# fig = plt.figure(figsize=(15,20))\n",
    "# st = fig.suptitle(\"Moving Average with Z-score\", fontsize=22)\n",
    "# st.set_y(0.92)\n",
    "\n",
    "# #Plot training data results\n",
    "# ax11 = fig.add_subplot(311)\n",
    "# ax11.plot(restored_df['Close'][-400:].values, label='BTC Closing Returns')\n",
    "# ax11.plot(restored_df['pred_Close'][-400:].values, label='Predicted BTC Closing Returns')\n",
    "# ax11.set_title(\"Testing Data\", fontsize=18)\n",
    "# ax11.set_xlabel('Date')\n",
    "# ax11.set_ylabel('BTC Closing Returns')\n",
    "# ax11.legend(loc=\"best\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819a0b90-7a98-48e9-b408-6452577e8d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # draw with first 400 testing data prediction\n",
    "# seq_len = 128\n",
    "# fig = plt.figure(figsize=(15,20))\n",
    "# st = fig.suptitle(\"Moving Average with Z-score\", fontsize=22)\n",
    "# st.set_y(0.92)\n",
    "\n",
    "# #Plot training data results\n",
    "# ax11 = fig.add_subplot(311)\n",
    "# ax11.plot(restored_df['Close'][-200:].values, label='BTC Closing Returns')\n",
    "# ax11.plot(restored_df['pred_Close'][-200:].values, label='Predicted BTC Closing Returns')\n",
    "# ax11.set_title(\"Testing Data\", fontsize=18)\n",
    "# ax11.set_xlabel('Date')\n",
    "# ax11.set_ylabel('BTC Closing Returns')\n",
    "# ax11.legend(loc=\"best\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381e28c6-40ab-4194-bfab-3851d85d9c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restored_df[['Close','pred_Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce8dcde-86e0-4e17-ba2f-3f24a3ddd6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
